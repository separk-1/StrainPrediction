{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File â€œStrainTemperature.csvâ€ contains a dataset, with 7 columns and 337 rows.  \n",
    "- Col. 1 lists the strain measured in a structural member, in micro-strains, Î¼Îµ (i.e., in parts per million).  \n",
    "- Col. 2 to 7 list the temperature measured by 6 thermometers in different locations, in degree Celsius.  \n",
    "Each row refers to a specific time when all measures (of strain and temperature) are collected.\n",
    "Measures are collected every 30 minutes for one week (hence the rows are 337 = 7 Ã— 24 Ã— 2 + 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    69.754  22.681  23.836  24.512  25.141   23.65  24.048\n",
      "0   98.703  23.317  24.357  25.073  25.689  24.205  24.622\n",
      "1  104.404  23.945  24.926  25.564  26.028  24.741  25.121\n",
      "2  101.514  24.226  25.503  25.994  26.164  25.146  25.481\n",
      "3   99.808  24.432  26.114  26.177  26.272  25.443  25.765\n",
      "4  105.260  24.612  26.233  26.532  26.378  25.656  25.955\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 336 entries, 0 to 335\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   69.754  336 non-null    float64\n",
      " 1   22.681  336 non-null    float64\n",
      " 2   23.836  336 non-null    float64\n",
      " 3   24.512  336 non-null    float64\n",
      " 4   25.141  336 non-null    float64\n",
      " 5   23.65   336 non-null    float64\n",
      " 6   24.048  336 non-null    float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 18.5 KB\n",
      "None\n",
      "           69.754      22.681      23.836      24.512      25.141       23.65  \\\n",
      "count  336.000000  336.000000  336.000000  336.000000  336.000000  336.000000   \n",
      "mean     0.693402   20.078354   20.151363   19.962071   20.033732   20.053473   \n",
      "std     76.068296    3.989084    4.632890    5.253171    4.890561    4.592934   \n",
      "min   -133.412000   13.850000   13.162000   11.752000   12.463000   13.365000   \n",
      "25%    -67.997000   16.092500   15.457500   14.651750   15.144500   15.383750   \n",
      "50%     -0.031500   20.209500   20.079000   19.893500   19.974000   20.117000   \n",
      "75%     63.802250   24.195000   24.808500   25.245500   25.055000   24.777000   \n",
      "max    171.542000   26.046000   27.402000   27.514000   27.268000   26.472000   \n",
      "\n",
      "           24.048  \n",
      "count  336.000000  \n",
      "mean    20.069295  \n",
      "std      4.646820  \n",
      "min     13.236000  \n",
      "25%     15.297500  \n",
      "50%     20.138500  \n",
      "75%     24.715250  \n",
      "max     26.532000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "data = pd.read_csv(\"./data/StrainTemperature.csv\")\n",
    "\n",
    "# ë°ì´í„° êµ¬ì¡° í™•ì¸\n",
    "print(data.head())  # ë°ì´í„°ì˜ ì²« 5í–‰\n",
    "print(data.info())  # ë°ì´í„° ìœ í˜• ë° ê²°ì¸¡ì¹˜ í™•ì¸\n",
    "print(data.describe())  # ê¸°ë³¸ í†µê³„ ê°’\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Proprecessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê²°ì¸¡ê°’ì´ ìˆëŠ”ì§€ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.754    0\n",
      "22.681    0\n",
      "23.836    0\n",
      "24.512    0\n",
      "25.141    0\n",
      "23.65     0\n",
      "24.048    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ê²°ì¸¡ê°’ í™•ì¸\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# ê²°ì¸¡ê°’ ëŒ€ì²´ ë˜ëŠ” ì œê±°\n",
    "data = data.dropna()  # ê²°ì¸¡ê°’ ì œê±° (í•„ìš”ì‹œ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ëŒ€ì²´)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calibrate a linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all 6 temperatures and also a â€œconstant featureâ€, to infer the strain as a function of the temperatures.   \n",
    "What is the coefficient of determination ğ‘…^2 for this fitted model?  \n",
    "Briefly explain how the value of ğ‘…^2 is related to the uncertainty in inferring the strain.\n",
    "\n",
    "6ê°œì˜ ì˜¨ë„ì™€ í•¨ê»˜ \"ìƒìˆ˜ í•­(constant feature)\"ì„ ì‚¬ìš©í•˜ì—¬, ë³€í˜•ë¥ ì„ ì˜¨ë„ì˜ í•¨ìˆ˜ë¡œ ì¶”ì •í•˜ì‹­ì‹œì˜¤.\n",
    "ì´ ëª¨ë¸ì— ëŒ€í•œ ê²°ì •ê³„ìˆ˜ R^2 ê°’ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?\n",
    "ğ‘…^2 ê°’ì´ ë³€í˜•ë¥  ì¶”ì •ì˜ ë¶ˆí™•ì‹¤ì„±ê³¼ ì–´ë–»ê²Œ ê´€ë ¨ì´ ìˆëŠ”ì§€ ê°„ë‹¨íˆ ì„¤ëª…í•˜ì‹­ì‹œì˜¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9331336033622016\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ì…ë ¥(X)ì™€ ì¶œë ¥(y) ë¶„ë¦¬\n",
    "X = data.iloc[:, 1:]  # ì˜¨ë„ ë°ì´í„° (2~7ì—´)\n",
    "y = data.iloc[:, 0]   # ë³€í˜•ë¥  (1ì—´)\n",
    "\n",
    "# ë°ì´í„° ë¶„ë¦¬ (í•™ìŠµ/í…ŒìŠ¤íŠ¸)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ì˜ˆì¸¡ ë° í‰ê°€\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"R^2 Score:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ê²°ì •ê³„ìˆ˜ R^2ê°’  \n",
    "ëª¨ë¸ì˜ ê²°ì •ê³„ìˆ˜ R^2 ê°’ì€ 0.9331ì…ë‹ˆë‹¤.\n",
    "ì´ëŠ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ë³€ë™ì„± ì¤‘ ì•½ 93.31%ê°€ ì´ ì„ í˜• íšŒê·€ ëª¨ë¸ë¡œ ì„¤ëª…ëœë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
    "2. R^2ê°’ê³¼ ë¶ˆí™•ì‹¤ì„±ì˜ ê´€ê³„  \n",
    "R^2 ê°’ì€ ëª¨ë¸ì´ ì…ë ¥ ë°ì´í„°(ì˜¨ë„)ë¡œë¶€í„° ì¶œë ¥ ë°ì´í„°(ë³€í˜•ë¥ )ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ì„¤ëª…í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
    "ë†’ì€ R^2ê°’(1ì— ê°€ê¹Œìš´ ê°’)ì€ ëª¨ë¸ì´ ë°ì´í„°ì˜ ë³€ë™ì„±ì„ ì˜ ì„¤ëª…í•˜ë©°, ì˜ˆì¸¡ ê²°ê³¼ì˜ ë¶ˆí™•ì‹¤ì„±ì´ ì‘ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
    "ë‚®ì€ R^2ê°’ì€ ëª¨ë¸ì´ ë°ì´í„°ë¥¼ ì¶©ë¶„íˆ ì„¤ëª…í•˜ì§€ ëª»í•´, ì˜ˆì¸¡ ê²°ê³¼ì˜ ë¶ˆí™•ì‹¤ì„±ì´ ë” í¬ë‹¤ëŠ” ê²ƒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
    "ê²°ë¡   \n",
    "R^2 ê°’ì´ 0.9331ë¡œ ë†’ê¸° ë•Œë¬¸ì—, ì´ ëª¨ë¸ì€ ë³€í˜•ë¥ ì„ ì˜¨ë„ì˜ í•¨ìˆ˜ë¡œ íš¨ê³¼ì ìœ¼ë¡œ ì¶”ì •í•˜ê³  ìˆìœ¼ë©°, ë¶ˆí™•ì‹¤ì„±ì´ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, \n",
    "R^2 ê°’ë§Œìœ¼ë¡œ ëª¨ë¸ì˜ í’ˆì§ˆì„ ì™„ì „íˆ í‰ê°€í•  ìˆ˜ëŠ” ì—†ìœ¼ë¯€ë¡œ, ì”ì°¨ ë¶„ì„ ë° ë‹¤ì¤‘ê³µì„ ì„± ë¬¸ì œë„ ì¶”ê°€ë¡œ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build a 95% confidence interval for each of the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly summarize the meaning of such intervals and discuss why are â€œlargeâ€ (if they are indeed large).\n",
    "\n",
    "ì˜¨ë„ì™€ ë³€í˜•ë¥  ê°„ì˜ ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê° ë§¤ê°œë³€ìˆ˜ì— ëŒ€í•´ 95% ì‹ ë¢°êµ¬ê°„ì„ êµ¬ì¶•í•˜ì‹­ì‹œì˜¤.  \n",
    "ê·¸ëŸ¬í•œ ì‹ ë¢°êµ¬ê°„ì˜ ì˜ë¯¸ë¥¼ ê°„ë‹¨íˆ ìš”ì•½í•˜ê³ , ë§Œì•½ ì‹ ë¢°êµ¬ê°„ì´ \"í¬ë‹¤ë©´\" ê·¸ ì´ìœ ë¥¼ ë…¼ì˜í•˜ì‹­ì‹œì˜¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 69.754   R-squared:                       0.932\n",
      "Model:                            OLS   Adj. R-squared:                  0.931\n",
      "Method:                 Least Squares   F-statistic:                     751.1\n",
      "Date:                Tue, 07 Jan 2025   Prob (F-statistic):          1.17e-188\n",
      "Time:                        02:24:59   Log-Likelihood:                -1480.2\n",
      "No. Observations:                 336   AIC:                             2974.\n",
      "Df Residuals:                     329   BIC:                             3001.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       -319.7674     14.606    -21.894      0.000    -348.499    -291.035\n",
      "22.681         8.2873     11.235      0.738      0.461     -13.814      30.389\n",
      "23.836       -15.4748     11.606     -1.333      0.183     -38.306       7.356\n",
      "24.512        -6.8850     11.674     -0.590      0.556     -29.850      16.080\n",
      "25.141        -2.9118      9.572     -0.304      0.761     -21.741      15.918\n",
      "23.65        -77.9348     16.793     -4.641      0.000    -110.971     -44.899\n",
      "24.048       110.8431     37.371      2.966      0.003      37.327     184.359\n",
      "==============================================================================\n",
      "Omnibus:                        3.094   Durbin-Watson:                   0.597\n",
      "Prob(Omnibus):                  0.213   Jarque-Bera (JB):                2.893\n",
      "Skew:                           0.162   Prob(JB):                        0.235\n",
      "Kurtosis:                       2.682   Cond. No.                     1.96e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.96e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "95% Confidence Intervals:\n",
      "          Lower Bound  Upper Bound\n",
      "Constant  -348.499443  -291.035435\n",
      "22.681     -13.814045    30.388559\n",
      "23.836     -38.306146     7.356490\n",
      "24.512     -29.849699    16.079676\n",
      "25.141     -21.741205    15.917591\n",
      "23.65     -110.970924   -44.898649\n",
      "24.048      37.327304   184.358797\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "# ë°ì´í„° ì¤€ë¹„ (ë…ë¦½ ë³€ìˆ˜ì™€ ì¢…ì† ë³€ìˆ˜ ì„¤ì •)\n",
    "X = data.iloc[:, 1:]  # ì˜¨ë„ ë°ì´í„° (2~7ì—´)\n",
    "y = data.iloc[:, 0]   # ë³€í˜•ë¥  (1ì—´)\n",
    "\n",
    "# ìƒìˆ˜ í•­ ì¶”ê°€ (StatsmodelsëŠ” ìƒìˆ˜ í•­ì„ ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€í•´ì•¼ í•¨)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# ì„ í˜• íšŒê·€ ëª¨ë¸ í”¼íŒ…\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(model.summary())\n",
    "\n",
    "# 95% ì‹ ë¢°êµ¬ê°„ ì¶”ì¶œ\n",
    "confidence_intervals = model.conf_int(alpha=0.05)  # 95% ì‹ ë¢°êµ¬ê°„\n",
    "confidence_intervals.columns = ['Lower Bound', 'Upper Bound']\n",
    "confidence_intervals.index = ['Constant'] + list(data.columns[1:])  # ë³€ìˆ˜ ì´ë¦„ ì¶”ê°€\n",
    "\n",
    "print(\"\\n95% Confidence Intervals:\")\n",
    "print(confidence_intervals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 95% ì‹ ë¢°êµ¬ê°„  \n",
    "ê²°ê³¼ì—ì„œ ê° ë³€ìˆ˜ì˜ 95% ì‹ ë¢°êµ¬ê°„ì€ ë§ˆì§€ë§‰ ë‘ ì—´ [0.025, 0.975]ì— í‘œì‹œë©ë‹ˆë‹¤.  \n",
    "\n",
    "ì˜ˆì‹œ:  \n",
    "const (ìƒìˆ˜ í•­)ì˜ ì‹ ë¢°êµ¬ê°„: [-348.499, -291.035]  \n",
    "ì²« ë²ˆì§¸ ë³€ìˆ˜(22.681)ì˜ ì‹ ë¢°êµ¬ê°„: [-13.814, 30.389]  \n",
    "ë§ˆì§€ë§‰ ë³€ìˆ˜(24.048)ì˜ ì‹ ë¢°êµ¬ê°„: [37.327, 184.359]  \n",
    "ì‹ ë¢°êµ¬ê°„ì˜ ì˜ë¯¸ëŠ” í•´ë‹¹ ê³„ìˆ˜ê°€ 95% í™•ë¥ ë¡œ ì´ ë²”ìœ„ ë‚´ì— ì¡´ì¬í•  ê²ƒì´ë¼ëŠ” ê²ƒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  \n",
    "\n",
    "2. ê³„ìˆ˜ì˜ ìœ ì˜ì„±  \n",
    "P>|t| ê°’ì€ ê° ë³€ìˆ˜ì˜ ê³„ìˆ˜ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œì§€ ì—¬ë¶€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  \n",
    "ì¼ë°˜ì ìœ¼ë¡œ   \n",
    "p-ê°’ì´ 0.05ë³´ë‹¤ ì‘ìœ¼ë©´ í•´ë‹¹ ê³„ìˆ˜ê°€ ìœ ì˜ë¯¸í•˜ë‹¤ê³  íŒë‹¨í•©ë‹ˆë‹¤.  \n",
    "ê²°ê³¼ ë¶„ì„:  \n",
    "const (ìƒìˆ˜ í•­): p=0.000, ìœ ì˜ë¯¸.  \n",
    "ë§ˆì§€ë§‰ ë³€ìˆ˜(24.048): p=0.003, ìœ ì˜ë¯¸.  \n",
    "ë‹¤ë¥¸ ë³€ìˆ˜ë“¤ì€ p>0.05ë¡œ ìœ ì˜ë¯¸í•˜ì§€ ì•ŠìŒ.  \n",
    "\n",
    "3. ì‹ ë¢°êµ¬ê°„ í¬ê¸°  \n",
    "ì‹ ë¢°êµ¬ê°„ì´ í¬ë‹¤ëŠ” ê²ƒì€ í•´ë‹¹ ê³„ìˆ˜ ì¶”ì •ì¹˜ì˜ ë¶ˆí™•ì‹¤ì„±ì´ í¬ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.  \n",
    "ì˜ˆë¥¼ ë“¤ì–´:  \n",
    "ì²« ë²ˆì§¸ ë³€ìˆ˜(22.681)ì˜ ì‹ ë¢°êµ¬ê°„ì€ **[-13.814, 30.389]**ë¡œ ë„“ì€ ë²”ìœ„ë¥¼ ê°€ì§‘ë‹ˆë‹¤.  \n",
    "ì´ëŠ” ëª¨ë¸ì´ í•´ë‹¹ ë³€ìˆ˜ì˜ ì˜í–¥ì„ ì •í™•íˆ ì¶”ì •í•˜ì§€ ëª»í•˜ê³  ìˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  \n",
    "\n",
    "4. ì™œ ì‹ ë¢°êµ¬ê°„ì´ í´ê¹Œ?  \n",
    "ë‹¤ì¤‘ê³µì„ ì„±: ë…ë¦½ ë³€ìˆ˜ë“¤ ê°„ì— ìƒê´€ê´€ê³„ê°€ ë†’ìœ¼ë©´, íŠ¹ì • ë³€ìˆ˜ì˜ ê³„ìˆ˜ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ì¶”ì •í•˜ê¸° ì–´ë ¤ì›Œì§‘ë‹ˆë‹¤.  \n",
    "ë°ì´í„° í’ˆì§ˆ: ë°ì´í„°ì˜ ìƒ˜í”Œ í¬ê¸°ê°€ ì‘ê±°ë‚˜, ë…¸ì´ì¦ˆê°€ ë§ì„ ê²½ìš° ì¶”ì •ê°’ì˜ ë¶ˆí™•ì‹¤ì„±ì´ ì»¤ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
    "ë³€ìˆ˜ì˜ ë‚®ì€ ì„¤ëª…ë ¥: í•´ë‹¹ ë³€ìˆ˜ê°€ ì¢…ì† ë³€ìˆ˜(ë³€í˜•ë¥ )ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ í¬ì§€ ì•Šì„ ê²½ìš°.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Investigate the issue of â€œmulticollinearity.â€ Compute the Variance Inflation Factor (VIF) for each of the temperatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, you need to regress the temperatures recorded by each thermometer ğ‘– against those by all\n",
    "other thermometers, compute the coefficient of determination of that regression, ğ‘…^2, and then use formula []. Briefly summarize the meaning of VIFs and draw some conclusions\n",
    "about the temperatures being â€œindependentâ€ features or, on the contrary, â€œredundantâ€ features.\n",
    "\n",
    "ì´ì œ ë‹¤ì¤‘ê³µì„ ì„±(multicollinearity) ë¬¸ì œë¥¼ ì¡°ì‚¬í•˜ì‹­ì‹œì˜¤. ê° ì˜¨ë„ ë³€ìˆ˜ì— ëŒ€í•´ **ë¶„ì‚° íŒ½ì°½ ìš”ì¸(VIF, Variance Inflation Factor)**ì„ ê³„ì‚°í•˜ì‹­ì‹œì˜¤.  \n",
    "VIFì— ëŒ€í•œ ì„¤ëª…ì€ ë‹¤ìŒ ë§í¬ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: https://en.wikipedia.org/wiki/Variance_inflation_factor.   \n",
    "ì´ë¥¼ ìˆ˜í–‰í•˜ë ¤ë©´, ê° ì˜¨ë„ê³„ iì— ëŒ€í•´ í•´ë‹¹ ì˜¨ë„ë¥¼ ë‚˜ë¨¸ì§€ ì˜¨ë„ë“¤ì— ëŒ€í•´ íšŒê·€(regress)í•˜ê³ , í•´ë‹¹ íšŒê·€ì˜ ê²°ì •ê³„ìˆ˜ R^2 ë¥¼ ê³„ì‚°í•˜ì‹­ì‹œì˜¤.   \n",
    "ê·¸ëŸ° ë‹¤ìŒ, ë‹¤ìŒ ê³µì‹ì„ ì‚¬ìš©í•˜ì—¬ VIFë¥¼ ê³„ì‚°í•˜ì‹­ì‹œì˜¤:  \n",
    "VIFì˜ ì˜ë¯¸ë¥¼ ê°„ë‹¨íˆ ìš”ì•½í•˜ê³ , ì˜¨ë„ê°€ \"ë…ë¦½ì ì¸ íŠ¹ì„±(independent features)\"ì¸ì§€, ë˜ëŠ” \"ì¤‘ë³µëœ íŠ¹ì„±(redundant features)\"ì¸ì§€ì— ëŒ€í•œ ê²°ë¡ ì„ ë„ì¶œí•˜ì‹­ì‹œì˜¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature           VIF\n",
      "0  22.681   1678.481395\n",
      "1  23.836   2416.019796\n",
      "2  24.512   3142.669321\n",
      "3  25.141   1831.153298\n",
      "4   23.65   4971.569075\n",
      "5  24.048  25200.370504\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# ë°ì´í„° ì¤€ë¹„ (ì˜¨ë„ ë³€ìˆ˜ë§Œ ì„ íƒ)\n",
    "X = data.iloc[:, 1:]  # ì˜¨ë„ ë°ì´í„° (2~7ì—´)\n",
    "X_columns = X.columns\n",
    "\n",
    "# VIF ê³„ì‚°\n",
    "vif_values = []\n",
    "\n",
    "for i in range(X.shape[1]):\n",
    "    # í˜„ì¬ ë³€ìˆ˜(i)ë¥¼ ì¢…ì† ë³€ìˆ˜ë¡œ ì„¤ì •, ë‚˜ë¨¸ì§€ë¥¼ ë…ë¦½ ë³€ìˆ˜ë¡œ ì„¤ì •\n",
    "    y = X.iloc[:, i]\n",
    "    X_temp = X.drop(X.columns[i], axis=1)\n",
    "    \n",
    "    # ì„ í˜• íšŒê·€ ëª¨ë¸ í•™ìŠµ\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_temp, y)\n",
    "    \n",
    "    # ê²°ì •ê³„ìˆ˜ R^2 ê³„ì‚°\n",
    "    r_squared = model.score(X_temp, y)\n",
    "    \n",
    "    # VIF ê³„ì‚°\n",
    "    vif = 1 / (1 - r_squared)\n",
    "    vif_values.append(vif)\n",
    "\n",
    "# VIF ê°’ì„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì •ë¦¬\n",
    "vif_data = pd.DataFrame({\n",
    "    \"Feature\": X_columns,\n",
    "    \"VIF\": vif_values\n",
    "})\n",
    "\n",
    "print(vif_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance Inflation Factor (VIF):\n",
      "  Variable            VIF\n",
      "0   22.681   43134.207218\n",
      "1   23.836   47878.049733\n",
      "2   24.512   45798.432010\n",
      "3   25.141   29565.418107\n",
      "4    23.65   85779.767266\n",
      "5   24.048  481470.634236\n"
     ]
    }
   ],
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© (ê²€ì¦ì¦)\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pandas as pd\n",
    "\n",
    "# ë°ì´í„° ì¤€ë¹„ (ì˜¨ë„ ë³€ìˆ˜ë§Œ ì„ íƒ)\n",
    "X = data.iloc[:, 1:]  # ì˜¨ë„ ë°ì´í„° (2~7ì—´)\n",
    "\n",
    "# VIF ê³„ì‚°\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = X.columns  # ë³€ìˆ˜ ì´ë¦„\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"Variance Inflation Factor (VIF):\")\n",
    "print(vif_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIF(Variance Inflation Factor)ëŠ” íŠ¹ì • ë…ë¦½ ë³€ìˆ˜ê°€ ë‹¤ë¥¸ ë…ë¦½ ë³€ìˆ˜ë“¤ê³¼ ì–¼ë§ˆë‚˜ ìƒê´€ë˜ì–´ ìˆëŠ”ì§€ë¥¼ ì¸¡ì •í•˜ëŠ” ì§€í‘œì…ë‹ˆë‹¤. VIF ê°’ì´ ë†’ì„ìˆ˜ë¡ í•´ë‹¹ ë³€ìˆ˜ëŠ” ë‹¤ë¥¸ ë³€ìˆ˜ë“¤ê³¼ ê°•í•œ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§€ë©°, ë…ë¦½ì ì´ë¼ê¸°ë³´ë‹¤ëŠ” ì¤‘ë³µëœ íŠ¹ì„±ìœ¼ë¡œ ì‘ìš©í•˜ê³  ìˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ VIF ê°’ì´ 10ì„ ì´ˆê³¼í•˜ë©´ ë‹¤ì¤‘ê³µì„ ì„±(multicollinearity) ë¬¸ì œê°€ ìˆë‹¤ê³  ê°„ì£¼ë©ë‹ˆë‹¤.\n",
    "\n",
    "í˜„ì¬ ë¶„ì„ ê²°ê³¼ì—ì„œ ëª¨ë“  ì˜¨ë„ ë³€ìˆ˜ì˜ VIF ê°’ì´ ë§¤ìš° ë†’ê²Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤(ìµœì†Œ 29,565ì—ì„œ ìµœëŒ€ 481,470). ì´ëŠ” ëª¨ë“  ì˜¨ë„ ë³€ìˆ˜ë“¤ì´ ì„œë¡œ ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©°, \"ë…ë¦½ì ì¸ íŠ¹ì„±(independent features)\"ì´ ì•„ë‹ˆë¼ \"ì¤‘ë³µëœ íŠ¹ì„±(redundant features)\"ìœ¼ë¡œ ê°„ì£¼ë  ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì¤‘ë³µì„±ì€ íšŒê·€ ëª¨ë¸ì—ì„œ ë³€ìˆ˜ë“¤ì˜ ê°œë³„ì ì¸ ì˜í–¥ì„ ì •í™•íˆ ì¶”ì •í•˜ëŠ” ê²ƒì„ ì–´ë µê²Œ ë§Œë“¤ë©°, ëª¨ë¸ì˜ ì•ˆì •ì„±ê³¼ ì‹ ë¢°ì„±ì„ ì €í•˜ì‹œí‚¬ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. address and â€œsolveâ€ the issue of multicollinearity, by modifying the model and/or the set of inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 ë‹¤ì¤‘ê³µì„ ì„±ì„ í•´ê²°í•´ì•¼ í•˜ëŠ” ì´ìœ \n",
    "ë‹¤ì¤‘ê³µì„ ì„±ì„ í•´ê²°í•˜ëŠ” ì´ìœ ëŠ” ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë©°, í˜„ì¬ ë¶„ì„ì—ì„œëŠ” ì•„ë˜ì™€ ê°™ì€ ì´ìœ ê°€ ëª¨ë‘ ê´€ë ¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "1) ë³€í˜•ë¥  ì¶”ì •ì˜ ê°œì„ \n",
    "ë‹¤ì¤‘ê³µì„ ì„±ì€ ë…ë¦½ ë³€ìˆ˜ ê°„ ë†’ì€ ìƒê´€ê´€ê³„ë¡œ ì¸í•´ ëª¨ë¸ì´ ê° ë³€ìˆ˜ì˜ ê°œë³„ì ì¸ ì˜í–¥ì„ ì •í™•íˆ ì¶”ì •í•˜ì§€ ëª»í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ë©´ ë³€í˜•ë¥  ì¶”ì •ì˜ ì •í™•ë„ë¥¼ ë†’ì´ê³  ëª¨ë¸ì˜ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "2) ë” ë‹¨ìˆœí•œ ëª¨ë¸ íšë“\n",
    "ë‹¤ì¤‘ê³µì„ ì„±ì´ ì¡´ì¬í•˜ë©´ ë¶ˆí•„ìš”í•˜ê²Œ ì¤‘ë³µëœ ë³€ìˆ˜ë¥¼ í¬í•¨í•˜ê²Œ ë˜ì–´ ëª¨ë¸ì´ ë³µì¡í•´ì§‘ë‹ˆë‹¤. ì´ëŸ¬í•œ ë³€ìˆ˜ë¥¼ ì œê±°í•˜ê±°ë‚˜ ì°¨ì› ì¶•ì†Œ ê¸°ë²•ì„ ì ìš©í•˜ë©´ ëª¨ë¸ì´ ë‹¨ìˆœí™”ë˜ë©´ì„œë„ ì„±ëŠ¥ì„ ìœ ì§€í•˜ê±°ë‚˜ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "3) ë³€í˜•ë¥ ê³¼ íŠ¹ì • ì˜¨ë„ ê°„ ê´€ê³„ ì´í•´\n",
    "ë‹¤ì¤‘ê³µì„ ì„±ì´ ìˆìœ¼ë©´ ë³€ìˆ˜ë“¤ ê°„ ìƒê´€ê´€ê³„ë¡œ ì¸í•´ íŠ¹ì • ë³€ìˆ˜ì˜ ê°œë³„ì ì¸ ì˜í–¥ì„ í•´ì„í•˜ê¸° ì–´ë ¤ì›Œì§‘ë‹ˆë‹¤. ë‹¤ì¤‘ê³µì„ ì„±ì„ ì¤„ì´ë©´ ë³€í˜•ë¥ ì— íŠ¹ì • ì˜¨ë„ê°€ ì–¼ë§ˆë‚˜ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ë” ëª…í™•íˆ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "4) ëª¨ë¸ ë§¤ê°œë³€ìˆ˜ì˜ ë¶ˆí™•ì‹¤ì„± ê°ì†Œ\n",
    "ë‹¤ì¤‘ê³µì„ ì„±ì€ íšŒê·€ ëª¨ë¸ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ë¶ˆì•ˆì •í•˜ê²Œ ë§Œë“¤ì–´, ë§¤ê°œë³€ìˆ˜ ì¶”ì •ì¹˜ì˜ ì‹ ë¢°êµ¬ê°„ì„ ë„“ê²Œ í•˜ê³  ëª¨ë¸ì˜ ì˜ˆì¸¡ ì‹ ë¢°ë„ë¥¼ ì €í•˜ì‹œí‚µë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ë©´ ë§¤ê°œë³€ìˆ˜ ì¶”ì •ì˜ ë¶ˆí™•ì‹¤ì„±ì„ ì¤„ì´ê³  ëª¨ë¸ì˜ ì•ˆì •ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê²°ë¡ ì ìœ¼ë¡œ, ë‹¤ì¤‘ê³µì„ ì„± ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ê²ƒì€ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê°œì„ í•˜ê³ , í•´ì„ ê°€ëŠ¥ì„±ì„ ë†’ì´ë©°, ëª¨ë¸ ë§¤ê°œë³€ìˆ˜ì˜ ì•ˆì •ì„±ê³¼ ì‹ ë¢°ì„±ì„ í™•ë³´í•˜ê¸° ìœ„í•œ ì¤‘ìš”í•œ ê³¼ì •ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 ë‹¤ì¤‘ê³µì„ ì„± í•´ê²°ì„ ìœ„í•œ ê¸°ë²• 1) Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIFê°€ ë†’ì€ ë³€ìˆ˜ ì œê±°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF Before:\n",
      "  Feature            VIF\n",
      "0  22.681   43134.207218\n",
      "1  23.836   47878.049733\n",
      "2  24.512   45798.432010\n",
      "3  25.141   29565.418107\n",
      "4   23.65   85779.767266\n",
      "5  24.048  481470.634236\n",
      "R^2 Score After Subset Selection: 0.9999582081308571\n",
      "VIF After:\n",
      "  Feature           VIF\n",
      "0  22.681   8361.708108\n",
      "1  23.836  13648.207919\n",
      "2  24.512   9068.252530\n",
      "3  25.141    345.288694\n",
      "4   23.65  84211.420734\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# VIF ê³„ì‚° í•¨ìˆ˜\n",
    "def calculate_vif(X):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif_data\n",
    "\n",
    "# ì´ˆê¸° VIF ê³„ì‚°\n",
    "vif_before = calculate_vif(X)\n",
    "print(\"VIF Before:\")\n",
    "print(vif_before)\n",
    "\n",
    "# VIFê°€ ê°€ì¥ ë†’ì€ ë³€ìˆ˜ ì œê±° (ì˜ˆ: \"24.048\")\n",
    "X_subset = X.drop(\"24.048\", axis=1)\n",
    "\n",
    "# ìˆ˜ì •ëœ ë°ì´í„°ë¡œ ëª¨ë¸ ì¬í•™ìŠµ\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_subset, y, test_size=0.2, random_state=42)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# R^2 ê²°ê³¼ ì¶œë ¥\n",
    "print(\"R^2 Score After Subset Selection:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# ìƒˆë¡œìš´ VIF ê³„ì‚°\n",
    "vif_after = calculate_vif(X_subset)\n",
    "print(\"VIF After:\")\n",
    "print(vif_after)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 ë‹¤ì¤‘ê³µì„ ì„± í•´ê²°ì„ ìœ„í•œ ê¸°ë²• 2) PCA  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PCAë¥¼ ì‚¬ìš©í•´ ì°¨ì›ì„ ì¶•ì†Œí•˜ê³ , ë‹¤ì¤‘ê³µì„ ì„±ì„ ì œê±°í•œ ìƒˆë¡œìš´ ë³€ìˆ˜ë¡œ ëª¨ë¸ì„ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score After PCA: 0.99995625124426\n",
      "Explained Variance Ratio: [0.98406508 0.0133762 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ë°ì´í„° ìŠ¤ì¼€ì¼ë§\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# PCA ì ìš© (ì£¼ì„±ë¶„ ìˆ˜ ì„¤ì •, ì˜ˆ: 2ê°œ)\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# PCA ì´í›„ ëª¨ë¸ í•™ìŠµ\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# R^2 ê²°ê³¼ ì¶œë ¥\n",
    "print(\"R^2 Score After PCA:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# PCA ë³€ë™ì„± ì„¤ëª… ë¹„ìœ¨\n",
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4 ë‹¤ì¤‘ê³µì„ ì„± í•´ê²°ì„ ìœ„í•œ ê¸°ë²• 3) Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score with Ridge Regression: 0.999954993143469\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# ë¦¿ì§€ íšŒê·€ ëª¨ë¸\n",
    "ridge = Ridge(alpha=1.0)  # ì•ŒíŒŒ ê°’ì€ ì •ê·œí™” ê°•ë„ë¥¼ ì¡°ì ˆ\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "\n",
    "# R^2 ê²°ê³¼ ì¶œë ¥\n",
    "print(\"R^2 Score with Ridge Regression:\", r2_score(y_test, y_pred_ridge))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5 ë‹¤ì¤‘ê³µì„ ì„± í•´ê²°ì„ ìœ„í•œ ê¸°ë²• 4) Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score with Lasso Regression: 0.9996497233047609\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# ë¼ì˜ íšŒê·€ ëª¨ë¸\n",
    "lasso = Lasso(alpha=0.1)  # ì•ŒíŒŒ ê°’ì€ ì •ê·œí™” ê°•ë„ë¥¼ ì¡°ì ˆ\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "\n",
    "# R^2 ê²°ê³¼ ì¶œë ¥\n",
    "print(\"R^2 Score with Lasso Regression:\", r2_score(y_test, y_pred_lasso))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**6.2 Subset Selection**\n",
    "ë°©ë²•:\n",
    "- VIFê°€ ê°€ì¥ ë†’ì€ ë³€ìˆ˜(24.048)ë¥¼ ì œê±°í•˜ê³  ëª¨ë¸ì„ ì¬í•™ìŠµ.\n",
    "ê²°ê³¼:\n",
    "- RÂ²: **0.9999**ë¡œ ì—¬ì „íˆ ë§¤ìš° ë†’ì€ ì„¤ëª…ë ¥ì„ ìœ ì§€.\n",
    "- VIF ê°’: ë‹¤ë¥¸ ë³€ìˆ˜ë“¤ì˜ VIF ê°’ì´ ì—¬ì „íˆ ë†’ìœ¼ë‚˜, ì¼ë¶€ ê°ì†Œë¥¼ í™•ì¸.\n",
    "\n",
    "ê²°ë¡ :\n",
    "- íŠ¹ì • ë³€ìˆ˜ë¥¼ ì œê±°í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë‹¤ì¤‘ê³µì„ ì„±ì„ ì¼ë¶€ ì™„í™”í•  ìˆ˜ ìˆì§€ë§Œ, ì™„ë²½íˆ í•´ê²°ë˜ì§€ëŠ” ì•ŠìŒ. ì¶”ê°€ì ì¸ ë³€ìˆ˜ ì œê±° ë˜ëŠ” ë‹¤ë¥¸ ê¸°ë²•ê³¼ì˜ ì¡°í•©ì´ í•„ìš”.\n",
    "\n",
    "---\n",
    "\n",
    "**6.3 PCA (Principal Component Analysis)**\n",
    "ë°©ë²•:\n",
    "- ì£¼ì„±ë¶„ ë¶„ì„(PCA)ì„ í†µí•´ ì˜¨ë„ ë³€ìˆ˜ì˜ ì°¨ì›ì„ ì¶•ì†Œ(2ê°œì˜ ì£¼ìš” ì„±ë¶„ìœ¼ë¡œ ë³€í™˜).\n",
    "ê²°ê³¼:\n",
    "- RÂ²: **0.9999**ë¡œ ë†’ì€ ì„¤ëª…ë ¥ì„ ìœ ì§€.\n",
    "- Explained Variance Ratio: ì²« ë²ˆì§¸ ë‘ ê°œ ì£¼ì„±ë¶„ì´ **99% ì´ìƒ**ì˜ ë³€ë™ì„±ì„ ì„¤ëª….\n",
    "\n",
    "ê²°ë¡ :\n",
    "- PCAëŠ” ë‹¤ì¤‘ê³µì„ ì„±ì„ íš¨ê³¼ì ìœ¼ë¡œ ì œê±°í•˜ë©°, ë³€ìˆ˜ ìˆ˜ë¥¼ ì¤„ì´ê³ ë„ ëª¨ë¸ì˜ ì„¤ëª…ë ¥ì„ ìœ ì§€.\n",
    "- ë‹¤ì¤‘ê³µì„ ì„±ì„ í•´ê²°í•˜ë©´ì„œë„ ëª¨ë¸ ë³µì¡ì„±ì„ ì¤„ì´ëŠ” ë° ìœ ë¦¬.\n",
    "\n",
    "---\n",
    "\n",
    "**6.4 Ridge Regression**\n",
    "ë°©ë²•:\n",
    "- ë¦¿ì§€ íšŒê·€ë¥¼ í†µí•´ ì •ê·œí™”ë¥¼ ì ìš©.\n",
    "- ì•ŒíŒŒ ê°’: 1.0.\n",
    "ê²°ê³¼:\n",
    "- RÂ²: **0.9999**ë¡œ ë†’ì€ ì„¤ëª…ë ¥ì„ ìœ ì§€.\n",
    "\n",
    "ê²°ë¡ :\n",
    "- ë¦¿ì§€ íšŒê·€ëŠ” ë‹¤ì¤‘ê³µì„ ì„± ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë™ì‹œì— ëª¨ë¸ ì„±ëŠ¥ì„ ìœ ì§€.\n",
    "- ë³€ìˆ˜ ê°„ì˜ ì˜í–¥ì„ ëª¨ë‘ ìœ ì§€í•˜ë©´ì„œë„ ê°€ì¤‘ì¹˜ë¥¼ ì•ˆì •í™”.\n",
    "\n",
    "---\n",
    "\n",
    "### **6.5 Lasso Regression**\n",
    "ë°©ë²•:\n",
    "- ë¼ì˜ íšŒê·€ë¥¼ í†µí•´ ì •ê·œí™”ì™€ ë³€ìˆ˜ ì„ íƒì„ ë™ì‹œì— ìˆ˜í–‰.\n",
    "- ì•ŒíŒŒ ê°’: 0.1.\n",
    "ê²°ê³¼:\n",
    "- RÂ²: **0.9999**ë¡œ ë†’ì€ ì„¤ëª…ë ¥ì„ ìœ ì§€.\n",
    "\n",
    "ê²°ë¡ :\n",
    "- ë¼ì˜ íšŒê·€ëŠ” ë¶ˆí•„ìš”í•œ ë³€ìˆ˜ë¥¼ ìë™ìœ¼ë¡œ ì œê±°í•˜ë©°, ëª¨ë¸ ë‹¨ìˆœí™”ì™€ ë‹¤ì¤‘ê³µì„ ì„± ë¬¸ì œë¥¼ ë™ì‹œì— í•´ê²°.\n",
    "- ì•ŒíŒŒ ê°’ì— ë”°ë¼ ì„ íƒë˜ëŠ” ë³€ìˆ˜ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ.\n",
    "\n",
    "---\n",
    "\n",
    "**ì „ì²´ ê²°ë¡ **\n",
    "1. **Subset Selection**:\n",
    "   - ë³€ìˆ˜ ì œê±°ë¡œ ë‹¤ì¤‘ê³µì„ ì„±ì„ ì™„í™”í•  ìˆ˜ ìˆìœ¼ë‚˜, ê°€ì¥ ê°„ë‹¨í•œ ì ‘ê·¼ë²•.\n",
    "   - ë³€ìˆ˜ ì œê±°ëŠ” ë°ì´í„° í•´ì„ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŒ.\n",
    "\n",
    "2. **PCA**:\n",
    "   - ë‹¤ì¤‘ê³µì„ ì„±ì„ ì™„ì „íˆ ì œê±°í•˜ë©°, ëª¨ë¸ì˜ ì„¤ëª…ë ¥ì„ ìœ ì§€.\n",
    "   - ì°¨ì›ì„ ì¶•ì†Œí•˜ë¯€ë¡œ ëª¨ë¸ í•´ì„ë ¥ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ.\n",
    "\n",
    "3. **Ridge Regression**:\n",
    "   - ë‹¤ì¤‘ê³µì„ ì„±ì„ í•´ê²°í•˜ë©´ì„œ ëª¨ë“  ë³€ìˆ˜ë¥¼ ìœ ì§€.\n",
    "   - í•´ì„ ê°€ëŠ¥ì„±ì´ ë†’ìŒ.\n",
    "\n",
    "4. **Lasso Regression**:\n",
    "   - ë‹¤ì¤‘ê³µì„ ì„± í•´ê²°ê³¼ ë³€ìˆ˜ ì„ íƒì„ ë™ì‹œì— ìˆ˜í–‰.\n",
    "   - ê°€ì¥ í•´ì„ ê°€ëŠ¥í•˜ê³  ê°„ë‹¨í•œ ëª¨ë¸ì„ ìƒì„±í•  ìˆ˜ ìˆìŒ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¥ë‹¨ì  ë¹„êµ ë° ê²°ë¡ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Predict Future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ì„ í˜• íšŒê·€ë¥¼ ì‚¬ìš©í•˜ì—¬, í˜„ì¬ (ë˜ëŠ” ê³¼ê±°)ì˜ ì˜¨ë„ì™€ ë³€í˜•ë¥ ì„ í•¨ìˆ˜ë¡œ í•˜ì—¬ ë¯¸ë˜ì˜ ë³€í˜•ë¥ ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ê°œë°œí•˜ì‹­ì‹œì˜¤. (ë¯¸ë˜ ì‹œì ì—ì„œ ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì „ ì§ˆë¬¸ì—ì„œ ì œì•ˆí•œ ëª¨ë¸ê³¼ ê´€ë ¨í•˜ì—¬, ì˜ˆì¸¡ì˜ ì •í™•ë„ë¥¼ ì •ëŸ‰í™”í•˜ì‹­ì‹œì˜¤.\n",
    "ë¯¸ë˜ ë³€í˜•ë¥ ì— ëŒ€í•´ 95% ì‹ ë¢°êµ¬ê°„ì„ ì–´ë–»ê²Œ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆê¹Œ?\n",
    "ì´ë¥¼ ë‹µí•˜ê¸° ìœ„í•´, ì—°ì†ëœ ì‹œì ì—ì„œ ë³€í˜•ë¥ ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë…¸ì´ì¦ˆê°€ ìƒê´€ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŒì„ ê³ ë ¤í•˜ì‹­ì‹œì˜¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë…¸ì´ì¦ˆ ìƒê´€ì„± ë¬¸ì œë¥¼ ë¶„ì„í•˜ê³  ì´ê²ƒì´ ì´ˆë˜í•˜ëŠ” ê²°ê³¼ë¥¼ ì„¤ëª…í•˜ë©°, ë¯¸ë˜ ë³€í˜•ë¥ ì— ëŒ€í•œ ì‹ ë¢°êµ¬ê°„ì„ ì •ì˜í•  ë•Œ ì´ í˜„ìƒì„ ì–´ë–»ê²Œ ë°˜ì˜í•  ìˆ˜ ìˆì„ì§€ ë…¼ì˜í•˜ì‹­ì‹œì˜¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¤ì¤‘ê³µì„ ì„±ì´ ë§ˆì§€ë§‰ ë‘ ì§ˆë¬¸ì—ì„œ ì •ì˜ëœ ë¯¸ë˜ ë³€í˜•ë¥  ì˜ˆì¸¡ê³¼ ì–´ë–»ê²Œ ê´€ë ¨ë˜ì–´ ìˆëŠ”ì§€ ë…¼ì˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StrainPrediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
